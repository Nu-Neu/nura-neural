{
  "name": "WF-02: Agent 1 - IMTT Source Evaluation",
  "nodes": [
    {
      "parameters": {
        "path": "agent-source",
        "httpMethod": "POST",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook - Analyze Content",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [250, 300],
      "webhookId": "agent-source-webhook"
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "minutes",
              "minutesInterval": 30
            }
          ]
        }
      },
      "id": "schedule-trigger",
      "name": "Every 30 Minutes",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [250, 500]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT \n  c.content_id,\n  c.source_id,\n  c.url,\n  c.title,\n  c.content_text,\n  c.language,\n  c.detected_language,\n  c.text_direction,\n  c.author_name,\n  c.published_at,\n  c.word_count,\n  c.ingested_at,\n  s.source_id,\n  s.source_type,\n  s.identifier AS source_domain,\n  s.name AS source_name,\n  s.name_original AS source_name_original,\n  s.country AS source_country,\n  s.primary_language AS source_language,\n  s.credibility_tier AS current_tier,\n  s.description AS source_description,\n  se.independence AS prev_independence,\n  se.methodology AS prev_methodology,\n  se.transparency AS prev_transparency,\n  se.triangulation AS prev_triangulation,\n  se.overall_score AS prev_overall_score,\n  se.created_at AS last_evaluated_at\nFROM content c\nLEFT JOIN sources s ON c.source_id = s.source_id\nLEFT JOIN source_evaluations se ON s.source_id = se.source_id AND se.is_current = true\nWHERE c.content_id = $1::uuid\n  AND c.analysis_status = 'pending'\nLIMIT 1",
        "options": {
          "queryReplacement": "={{ [$json.body?.content_id || $json.query?.content_id] }}"
        }
      },
      "id": "get-content-webhook",
      "name": "Get Content (Webhook)",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [470, 300],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT \n  c.content_id,\n  c.source_id,\n  c.url,\n  c.title,\n  c.content_text,\n  c.language,\n  c.detected_language,\n  c.text_direction,\n  c.author_name,\n  c.published_at,\n  c.word_count,\n  c.ingested_at,\n  s.source_id,\n  s.source_type,\n  s.identifier AS source_domain,\n  s.name AS source_name,\n  s.name_original AS source_name_original,\n  s.country AS source_country,\n  s.primary_language AS source_language,\n  s.credibility_tier AS current_tier,\n  s.description AS source_description,\n  se.independence AS prev_independence,\n  se.methodology AS prev_methodology,\n  se.transparency AS prev_transparency,\n  se.triangulation AS prev_triangulation,\n  se.overall_score AS prev_overall_score,\n  se.created_at AS last_evaluated_at\nFROM content c\nLEFT JOIN sources s ON c.source_id = s.source_id\nLEFT JOIN source_evaluations se ON s.source_id = se.source_id AND se.is_current = true\nWHERE c.analysis_status = 'pending'\nORDER BY c.ingested_at ASC\nLIMIT 10",
        "options": {}
      },
      "id": "get-pending-batch",
      "name": "Get Pending Content (Batch)",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [470, 500],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true
          },
          "combinator": "and",
          "conditions": [
            {
              "leftValue": "={{ $input.all().length }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ]
        }
      },
      "id": "has-content",
      "name": "Has Content?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [690, 400]
    },
    {
      "parameters": {
        "batchSize": 1,
        "options": {}
      },
      "id": "process-each",
      "name": "Process Each Content",
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [910, 400]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://nura-search.search.windows.net/indexes/nura-claims/docs/search?api-version=2024-07-01",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n  count: true,\n  top: 5,\n  select: 'claim_id,claim_text_en,claim_type,source_credibility,extracted_at',\n  filter: \"source_credibility ne 'unverified'\",\n  search: $json.title || '',\n  queryType: 'simple'\n}) }}",
        "options": {
          "timeout": 10000
        }
      },
      "id": "search-context",
      "name": "Search Similar Content",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1130, 400],
      "credentials": {
        "httpHeaderAuth": {
          "id": "ai-search-auth",
          "name": "Azure AI Search"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Prepare context from similar content search\nconst content = $('Process Each Content').item.json;\nconst searchResults = $json?.value || [];\n\n// Format context from similar claims\nconst contextClaims = searchResults\n  .slice(0, 3)\n  .map(r => `- ${r.claim_text_en} (Source tier: ${r.source_credibility})`)\n  .join('\\n');\n\n// Truncate content for API limits\nconst maxContentLength = 12000;\nlet contentText = content.content_text || '';\nif (contentText.length > maxContentLength) {\n  contentText = contentText.slice(0, maxContentLength) + '\\n\\n[Content truncated due to length...]';\n}\n\n// Build the IMTT analysis prompt for Azure OpenAI\nconst chatInput = `Analyze the following content using the IMTT framework.\n\n**Source**: ${content.source_name || 'Unknown'} (${content.source_domain || 'Unknown domain'})\n**Source Country**: ${content.source_country || 'Unknown'}\n**Current Credibility Tier**: ${content.current_tier || 'unverified'}\n**Title**: ${content.title || 'No title'}\n**Language**: ${content.language || 'Unknown'}\n**Published**: ${content.published_at || 'Unknown date'}\n\n**Content**:\n${contentText}\n\n**Context - Similar Claims**:\n${contextClaims || 'No similar claims found in database.'}\n\nScore each IMTT pillar (0.0-1.0):\n- INDEPENDENCE: Is this source independent from political/financial actors?\n- METHODOLOGY: Does content follow journalistic standards?\n- TRANSPARENCY: Is ownership/funding/authorship disclosed?\n- TRIANGULATION: Is information cross-checked against other sources?\n\nExtract 3-7 verifiable claims and detect any propaganda techniques.\n\nRespond with JSON:\n{\n  \"imtt_scores\": {\n    \"independence\": { \"score\": 0.0-1.0, \"score_5\": 0-5, \"justification\": \"...\", \"signals\": [] },\n    \"methodology\": { \"score\": 0.0-1.0, \"score_5\": 0-5, \"justification\": \"...\", \"signals\": [] },\n    \"transparency\": { \"score\": 0.0-1.0, \"score_5\": 0-5, \"justification\": \"...\", \"signals\": [] },\n    \"triangulation\": { \"score\": 0.0-1.0, \"score_5\": 0-5, \"justification\": \"...\", \"signals\": [] }\n  },\n  \"total_score\": 0.0-1.0,\n  \"total_score_20\": 0-20,\n  \"credibility_tier\": \"authoritative|reliable|mixed|questionable|propaganda\",\n  \"tier_reasoning\": \"...\",\n  \"propaganda_techniques\": [{ \"technique\": \"...\", \"evidence\": \"...\", \"severity\": \"low|medium|high\" }],\n  \"claims\": [{ \"original_text\": \"...\", \"english_translation\": \"...\", \"language\": \"fa|ar|en\", \"claim_type\": \"concrete|attribution|causal|predictive|quantitative|narrative\", \"verifiability\": \"high|medium|low\", \"confidence\": 0.0-1.0, \"subject\": \"...\", \"requires_fact_check\": true|false }],\n  \"content_analysis\": { \"stance\": \"pro_regime|anti_regime|pro_western|anti_western|neutral|mixed\", \"stance_confidence\": 0.0-1.0, \"primary_topic\": \"...\", \"emotional_tone\": \"neutral|alarming|celebratory|critical|defensive\" },\n  \"overall_assessment\": \"...\",\n  \"confidence\": 0.0-1.0,\n  \"needs_escalation\": true|false,\n  \"escalation_reason\": \"...\"\n}`;\n\nreturn {\n  ...content,\n  content_text_truncated: contentText,\n  context_claims: contextClaims || 'No similar claims found in database.',\n  has_context: searchResults.length > 0,\n  chatInput: chatInput\n};"
      },
      "id": "prepare-context",
      "name": "Prepare Analysis Context",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1350, 400]
    },
    {
      "parameters": {
        "prompt": "={{ $json.chatInput }}",
        "hasOutputParser": false,
        "messages": {
          "messageValues": [
            {
              "message": "You are an expert media analyst specializing in evaluating news sources and content using the IMTT (Information Manipulation Typology Tool) framework.\n\nYou analyze content in Farsi (Persian), Arabic, and English. You MUST:\n1. Preserve original language text when extracting claims\n2. Provide English translations for all non-English content\n3. Be culturally aware of Iranian/Middle Eastern media landscape\n4. Recognize state-affiliated vs independent media signals\n\nYour evaluation must be evidence-based and cite specific examples from the content.\n\nRespond ONLY with valid JSON. No markdown code blocks, no explanation outside JSON."
            }
          ]
        }
      },
      "id": "gpt4o-imtt-analysis",
      "name": "Azure OpenAI IMTT Analysis",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.4,
      "position": [1570, 400],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 5000
    },
    {
      "parameters": {
        "model": "gpt-4o",
        "options": {
          "temperature": 0.3,
          "maxTokens": 4000,
          "timeout": 120000
        }
      },
      "id": "azure-openai-chat-model",
      "name": "Azure OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatAzureOpenAi",
      "typeVersion": 1,
      "position": [1650, 560],
      "credentials": {
        "azureOpenAiApi": {
          "id": "uyCPQWMhgIMY3zC7",
          "name": "Azure Open AI account 3"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Parse and validate LangChain Basic LLM Chain response\nconst content = $('Prepare Analysis Context').item.json;\nconst rawResponse = $json;\n\nlet analysis;\ntry {\n  // LangChain Basic LLM Chain response format: { text: '...' } or direct JSON\n  if (typeof rawResponse.text === 'string') {\n    analysis = JSON.parse(rawResponse.text);\n  } else if (typeof rawResponse.response?.text === 'string') {\n    analysis = JSON.parse(rawResponse.response.text);\n  } else if (rawResponse.choices && rawResponse.choices[0]?.message?.content) {\n    // Fallback for raw OpenAI response format\n    analysis = JSON.parse(rawResponse.choices[0].message.content);\n  } else if (typeof rawResponse.message?.content === 'string') {\n    analysis = JSON.parse(rawResponse.message.content);\n  } else if (typeof rawResponse.content === 'string') {\n    analysis = JSON.parse(rawResponse.content);\n  } else if (rawResponse.imtt_scores) {\n    // Already parsed JSON\n    analysis = rawResponse;\n  } else {\n    throw new Error('Unexpected response format: ' + JSON.stringify(Object.keys(rawResponse)));\n  }\n} catch (e) {\n  return {\n    content_id: content.content_id,\n    source_id: content.source_id,\n    parse_error: true,\n    error_message: e.message,\n    raw_response: JSON.stringify(rawResponse).slice(0, 500),\n    imtt_scores: {\n      independence: { score: 0.5, score_5: 3, justification: 'Parse error', signals: [] },\n      methodology: { score: 0.5, score_5: 3, justification: 'Parse error', signals: [] },\n      transparency: { score: 0.5, score_5: 3, justification: 'Parse error', signals: [] },\n      triangulation: { score: 0.5, score_5: 3, justification: 'Parse error', signals: [] }\n    },\n    total_score: 0.5,\n    credibility_tier: 'unverified',\n    propaganda_techniques: [],\n    claims: [],\n    confidence: 0.3,\n    needs_escalation: true,\n    escalation_reason: 'Parse error in Azure OpenAI response: ' + e.message\n  };\n}\n\nconst validateScore = (score, fallback = 0.5) => {\n  const num = parseFloat(score);\n  return isNaN(num) ? fallback : Math.max(0, Math.min(1, num));\n};\n\nconst imtt = analysis.imtt_scores || {};\nconst normalizedImtt = {\n  independence: {\n    score: validateScore(imtt.independence?.score),\n    score_5: Math.round(validateScore(imtt.independence?.score) * 5),\n    justification: imtt.independence?.justification || '',\n    signals: imtt.independence?.signals || []\n  },\n  methodology: {\n    score: validateScore(imtt.methodology?.score),\n    score_5: Math.round(validateScore(imtt.methodology?.score) * 5),\n    justification: imtt.methodology?.justification || '',\n    signals: imtt.methodology?.signals || []\n  },\n  transparency: {\n    score: validateScore(imtt.transparency?.score),\n    score_5: Math.round(validateScore(imtt.transparency?.score) * 5),\n    justification: imtt.transparency?.justification || '',\n    signals: imtt.transparency?.signals || []\n  },\n  triangulation: {\n    score: validateScore(imtt.triangulation?.score),\n    score_5: Math.round(validateScore(imtt.triangulation?.score) * 5),\n    justification: imtt.triangulation?.justification || '',\n    signals: imtt.triangulation?.signals || []\n  }\n};\n\nconst totalScore = (normalizedImtt.independence.score + normalizedImtt.methodology.score + normalizedImtt.transparency.score + normalizedImtt.triangulation.score) / 4;\nconst totalScore20 = normalizedImtt.independence.score_5 + normalizedImtt.methodology.score_5 + normalizedImtt.transparency.score_5 + normalizedImtt.triangulation.score_5;\n\nconst getTier = (score20) => {\n  if (score20 >= 18) return 'authoritative';\n  if (score20 >= 14) return 'reliable';\n  if (score20 >= 10) return 'mixed';\n  if (score20 >= 5) return 'questionable';\n  return 'propaganda';\n};\n\nconst mapTierToEnum = (tier) => {\n  const mapping = { 'authoritative': 'official', 'reliable': 'credible', 'mixed': 'unverified', 'questionable': 'partisan', 'propaganda': 'propaganda' };\n  return mapping[tier] || 'unverified';\n};\n\n// Model info from LangChain response\nconst modelUsed = rawResponse.llmOutput?.tokenUsage?.model || 'gpt-4o';\n\nconst credibilityTier = analysis.credibility_tier || getTier(totalScore20);\nconst claims = (analysis.claims || []).map((claim, idx) => ({\n  claim_index: idx,\n  original_text: claim.original_text || claim.english_translation || '',\n  english_translation: claim.english_translation || claim.original_text || '',\n  language: claim.language || content.language || 'en',\n  claim_type: claim.claim_type || 'narrative',\n  verifiability: claim.verifiability || 'medium',\n  confidence: validateScore(claim.confidence, 0.5),\n  subject: claim.subject || '',\n  requires_fact_check: claim.requires_fact_check || false\n}));\n\nconst propagandaTechniques = (analysis.propaganda_techniques || []).map(pt => ({\n  technique: pt.technique || 'unknown',\n  evidence: pt.evidence || '',\n  severity: pt.severity || 'low'\n}));\n\nconst propagandaRisk = propagandaTechniques.length === 0 ? 0 : Math.min(1, propagandaTechniques.reduce((sum, pt) => sum + ({ low: 0.1, medium: 0.25, high: 0.4 }[pt.severity] || 0.2), 0));\nconst confidence = validateScore(analysis.confidence, 0.5);\nconst needsEscalation = analysis.needs_escalation || confidence < 0.6 || propagandaRisk > 0.7;\n\nreturn {\n  content_id: content.content_id,\n  source_id: content.source_id,\n  url: content.url,\n  title: content.title,\n  language: content.language,\n  imtt_scores: normalizedImtt,\n  independence: normalizedImtt.independence.score,\n  methodology: normalizedImtt.methodology.score,\n  transparency: normalizedImtt.transparency.score,\n  triangulation: normalizedImtt.triangulation.score,\n  total_score: totalScore,\n  total_score_20: totalScore20,\n  overall_score: totalScore,\n  credibility_tier: credibilityTier,\n  credibility_tier_enum: mapTierToEnum(credibilityTier),\n  recommended_tier: mapTierToEnum(credibilityTier),\n  tier_reasoning: analysis.tier_reasoning || '',\n  content_analysis: analysis.content_analysis || {},\n  stance: analysis.content_analysis?.stance || 'neutral',\n  stance_confidence: validateScore(analysis.content_analysis?.stance_confidence, 0.5),\n  propaganda_techniques: propagandaTechniques,\n  propaganda_risk: propagandaRisk,\n  claims: claims,\n  claims_count: claims.length,\n  overall_assessment: analysis.overall_assessment || '',\n  confidence: confidence,\n  needs_escalation: needsEscalation,\n  escalation_reason: analysis.escalation_reason || (needsEscalation ? 'Low confidence or high propaganda risk' : null),\n  model_used: modelUsed,\n  evaluated_by: 'agent1',\n  evaluation_timestamp: new Date().toISOString(),\n  usage: rawResponse.llmOutput?.tokenUsage || null\n};"
      },
      "id": "parse-validate",
      "name": "Parse & Validate Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1790, 400]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE source_evaluations SET is_current = false WHERE source_id = $1::uuid AND is_current = true;\n\nINSERT INTO source_evaluations (\n  source_id, independence, methodology, transparency, triangulation,\n  overall_score, recommended_tier, reasoning, sample_content_ids,\n  model_used, evaluated_by, is_current\n) VALUES (\n  $1::uuid, $2, $3, $4, $5, $6, $7::credibility_tier, $8,\n  ARRAY[$9::uuid], $10, $11, true\n)\nRETURNING evaluation_id;",
        "options": {
          "queryReplacement": "={{ [\n  $json.source_id,\n  $json.independence,\n  $json.methodology,\n  $json.transparency,\n  $json.triangulation,\n  $json.overall_score,\n  $json.recommended_tier,\n  $json.tier_reasoning || $json.overall_assessment,\n  $json.content_id,\n  $json.model_used,\n  $json.evaluated_by\n] }}"
        }
      },
      "id": "upsert-source-evaluation",
      "name": "Upsert Source Evaluation",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2010, 400],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO content_evaluations (\n  content_id, stance, stance_confidence, propaganda_risk,\n  factuality_score, explanation, model_used, evaluated_by, is_current\n) VALUES (\n  $1::uuid, $2::stance, $3, $4, $5, $6, $7, $8, true\n)\nON CONFLICT (content_id) WHERE is_current = true\nDO UPDATE SET\n  stance = EXCLUDED.stance,\n  stance_confidence = EXCLUDED.stance_confidence,\n  propaganda_risk = EXCLUDED.propaganda_risk,\n  factuality_score = EXCLUDED.factuality_score,\n  explanation = EXCLUDED.explanation,\n  updated_at = NOW()\nRETURNING evaluation_id;",
        "options": {
          "queryReplacement": "={{ [\n  $json.content_id,\n  $json.stance || 'neutral',\n  $json.stance_confidence || 0.5,\n  $json.propaganda_risk || 0,\n  1 - ($json.propaganda_risk || 0),\n  $json.overall_assessment || '',\n  $json.model_used,\n  $json.evaluated_by\n] }}"
        }
      },
      "id": "upsert-content-evaluation",
      "name": "Upsert Content Evaluation",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2230, 400],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true
          },
          "combinator": "and",
          "conditions": [
            {
              "leftValue": "={{ $('Parse & Validate Response').item.json.claims_count }}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ]
        }
      },
      "id": "has-claims",
      "name": "Has Claims?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [2450, 400]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO claims (\n  content_id, claim_text, claim_text_en, language, claim_type,\n  confidence, subject_text, requires_verification\n)\nSELECT\n  $1::uuid,\n  (claim->>'original_text')::text,\n  (claim->>'english_translation')::text,\n  (claim->>'language')::text,\n  (claim->>'claim_type')::claim_type,\n  COALESCE((claim->>'confidence')::float, 0.5),\n  (claim->>'subject')::text,\n  COALESCE((claim->>'requires_fact_check')::boolean, false)\nFROM jsonb_array_elements($2::jsonb) AS claim\nON CONFLICT DO NOTHING\nRETURNING claim_id;",
        "options": {
          "queryReplacement": "={{ [\n  $('Parse & Validate Response').item.json.content_id,\n  JSON.stringify($('Parse & Validate Response').item.json.claims)\n] }}"
        }
      },
      "id": "insert-claims",
      "name": "Insert Claims",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2670, 300],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE content SET analysis_status = 'completed', updated_at = NOW() WHERE content_id = $1::uuid;",
        "options": {
          "queryReplacement": "={{ [$('Parse & Validate Response').item.json.content_id] }}"
        }
      },
      "id": "mark-completed",
      "name": "Mark Content Completed",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2890, 400],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true
          },
          "combinator": "and",
          "conditions": [
            {
              "leftValue": "={{ $('Parse & Validate Response').item.json.needs_escalation }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ]
        }
      },
      "id": "needs-escalation",
      "name": "Needs Escalation?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [3110, 400]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO escalations (\n  escalation_type, source_entity_id, source_entity_type,\n  reason, priority, status\n) VALUES (\n  'low_confidence', $1::uuid, 'content_evaluation',\n  $2, 'medium', 'pending'\n)\nRETURNING escalation_id;",
        "options": {
          "queryReplacement": "={{ [\n  $('Parse & Validate Response').item.json.content_id,\n  $('Parse & Validate Response').item.json.escalation_reason || 'Requires review'\n] }}"
        }
      },
      "id": "create-escalation",
      "name": "Create Escalation",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [3330, 300],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO analysis_log (\n  agent_name, run_type, started_at, completed_at, duration_ms,\n  items_processed, items_success, status, metadata, workflow_execution_id\n) VALUES (\n  'agent1', 'imtt_evaluation', $1, NOW(),\n  EXTRACT(EPOCH FROM (NOW() - $1::timestamp)) * 1000,\n  1, 1, 'completed',\n  $2::jsonb, $3\n);",
        "options": {
          "queryReplacement": "={{ [\n  $('Parse & Validate Response').item.json.evaluation_timestamp,\n  JSON.stringify({\n    content_id: $('Parse & Validate Response').item.json.content_id,\n    source_id: $('Parse & Validate Response').item.json.source_id,\n    credibility_tier: $('Parse & Validate Response').item.json.credibility_tier,\n    claims_extracted: $('Parse & Validate Response').item.json.claims_count,\n    needs_escalation: $('Parse & Validate Response').item.json.needs_escalation\n  }),\n  $executionId\n] }}"
        }
      },
      "id": "log-analysis",
      "name": "Log Analysis",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [3550, 400],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {},
      "id": "loop-done",
      "name": "Loop Done?",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [3770, 400]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify({\n  status: 'completed',\n  execution_id: $executionId,\n  content_id: $('Parse & Validate Response').item?.json?.content_id,\n  credibility_tier: $('Parse & Validate Response').item?.json?.credibility_tier,\n  claims_extracted: $('Parse & Validate Response').item?.json?.claims_count || 0,\n  timestamp: new Date().toISOString()\n}) }}",
        "options": {
          "responseCode": 200,
          "responseHeaders": {
            "entries": [
              {
                "name": "Content-Type",
                "value": "application/json"
              },
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "id": "respond-webhook",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [3990, 300]
    },
    {
      "parameters": {},
      "id": "end-schedule",
      "name": "End (Schedule)",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [3990, 500]
    },
    {
      "parameters": {},
      "id": "skip-no-claims",
      "name": "Skip (No Claims)",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [2670, 500]
    },
    {
      "parameters": {},
      "id": "skip-no-escalation",
      "name": "Skip (No Escalation)",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [3330, 500]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify({\n  status: 'no_content',\n  execution_id: $executionId,\n  message: 'No pending content found to analyze',\n  timestamp: new Date().toISOString()\n}) }}",
        "options": {
          "responseCode": 200,
          "responseHeaders": {
            "entries": [
              {
                "name": "Content-Type",
                "value": "application/json"
              },
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "id": "respond-no-content",
      "name": "Respond No Content",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [910, 550]
    }
  ],
  "connections": {
    "Webhook - Analyze Content": {
      "main": [
        [
          {
            "node": "Get Content (Webhook)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Every 30 Minutes": {
      "main": [
        [
          {
            "node": "Get Pending Content (Batch)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Content (Webhook)": {
      "main": [
        [
          {
            "node": "Has Content?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Pending Content (Batch)": {
      "main": [
        [
          {
            "node": "Has Content?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Content?": {
      "main": [
        [
          {
            "node": "Process Each Content",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Respond No Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Each Content": {
      "main": [
        [
          {
            "node": "Search Similar Content",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          },
          {
            "node": "End (Schedule)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Search Similar Content": {
      "main": [
        [
          {
            "node": "Prepare Analysis Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Analysis Context": {
      "main": [
        [
          {
            "node": "Azure OpenAI IMTT Analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Azure OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Azure OpenAI IMTT Analysis",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Azure OpenAI IMTT Analysis": {
      "main": [
        [
          {
            "node": "Parse & Validate Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse & Validate Response": {
      "main": [
        [
          {
            "node": "Upsert Source Evaluation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upsert Source Evaluation": {
      "main": [
        [
          {
            "node": "Upsert Content Evaluation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Upsert Content Evaluation": {
      "main": [
        [
          {
            "node": "Has Claims?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Claims?": {
      "main": [
        [
          {
            "node": "Insert Claims",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Skip (No Claims)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Insert Claims": {
      "main": [
        [
          {
            "node": "Mark Content Completed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Skip (No Claims)": {
      "main": [
        [
          {
            "node": "Mark Content Completed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Mark Content Completed": {
      "main": [
        [
          {
            "node": "Needs Escalation?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Needs Escalation?": {
      "main": [
        [
          {
            "node": "Create Escalation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Skip (No Escalation)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Escalation": {
      "main": [
        [
          {
            "node": "Log Analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Skip (No Escalation)": {
      "main": [
        [
          {
            "node": "Log Analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log Analysis": {
      "main": [
        [
          {
            "node": "Loop Done?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Done?": {
      "main": [
        [
          {
            "node": "Process Each Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": ""
  },
  "staticData": null,
  "tags": [
    {
      "name": "nura-neural",
      "createdAt": "2026-02-01T00:00:00.000Z",
      "updatedAt": "2026-02-01T00:00:00.000Z"
    },
    {
      "name": "agent1",
      "createdAt": "2026-02-01T00:00:00.000Z",
      "updatedAt": "2026-02-01T00:00:00.000Z"
    },
    {
      "name": "imtt-evaluation",
      "createdAt": "2026-02-01T00:00:00.000Z",
      "updatedAt": "2026-02-01T00:00:00.000Z"
    }
  ],
  "triggerCount": 2,
  "versionId": "1.0.0",
  "meta": {
    "templateCredsSetupCompleted": false,
    "instanceId": "nura-neural-instance"
  }
}
