{
  "name": "WF3: Trust Scoring Pipeline",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "minutes",
              "minutesInterval": 5
            }
          ]
        }
      },
      "id": "schedule-scoring",
      "name": "Schedule (5min)",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [260, 300],
      "notes": "Poll for enriched items every 5 minutes"
    },
    {
      "parameters": {
        "operation": "select",
        "query": "SELECT check_workflow_health('WF3_Trust_Scoring') as can_proceed",
        "options": {}
      },
      "id": "check-circuit",
      "name": "Check Circuit Breaker",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [480, 300],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "circuit-check",
              "leftValue": "={{ $json.can_proceed }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "if-circuit-open",
      "name": "IF Circuit Open",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [700, 300]
    },
    {
      "parameters": {
        "operation": "select",
        "query": "SELECT i.id, i.source_id, i.url, i.title, i.content, i.author, i.published_at,\n       i.embedding, i.ai_metadata, sp.base_score, sp.source_class, sp.name as source_name\nFROM items i\nLEFT JOIN source_profiles sp ON i.source_id = sp.id\nWHERE i.status = 'enriched' \nAND i.embedding IS NOT NULL\nAND i.processed_at > NOW() - interval '24 hours'\nORDER BY i.processed_at DESC\nLIMIT 20\nFOR UPDATE OF i SKIP LOCKED",
        "options": {}
      },
      "id": "get-enriched-items",
      "name": "Get Enriched Items",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [920, 300],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      },
      "notes": "Get up to 20 enriched items with source profile data"
    },
    {
      "parameters": {
        "jsCode": "// REQ-AI-001: Component 1 - Source Credibility (0-30 points)\n// Based on source_profiles.base_score and source_class\n\nconst item = $input.first().json;\n\n// Get base score from source profile (default to 50 if no source match)\nconst sourceBaseScore = item.base_score || 50;\nconst sourceClass = item.source_class || 'unknown';\n\n// Normalize to 0-30 scale (base_score is 0-100)\n// Class modifiers: 'wire' +5, 'quality' +3, 'tabloid' -5, 'state_media' -10\nlet classModifier = 0;\nswitch(sourceClass) {\n  case 'wire': classModifier = 5; break;\n  case 'quality': classModifier = 3; break;\n  case 'tabloid': classModifier = -5; break;\n  case 'state_media': classModifier = -10; break;\n  default: classModifier = 0;\n}\n\nconst c1_raw = (sourceBaseScore / 100) * 30 + classModifier;\nconst c1_score = Math.max(0, Math.min(30, c1_raw));\n\nreturn [{\n  json: {\n    ...item,\n    c1_source_credibility: c1_score,\n    c1_details: {\n      base_score: sourceBaseScore,\n      source_class: sourceClass,\n      class_modifier: classModifier\n    }\n  }\n}];"
      },
      "id": "component-1-source",
      "name": "C1: Source Credibility (0-30)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1140, 200],
      "notes": "REQ-AI-001: Source Credibility from source_profiles"
    },
    {
      "parameters": {
        "jsCode": "// REQ-AI-001 & REQ-AI-ML-004: Component 2 - Content Quality (0-25 points)\n// Analyze byline, dateline, citations, length, structure\n\nconst item = $input.first().json;\nconst content = item.content || '';\nconst metadata = item.ai_metadata || {};\n\nlet score = 0;\nconst details = {};\n\n// 1. Byline presence (+5 points)\nconst hasAuthor = Boolean(item.author || metadata.author);\nif (hasAuthor) {\n  score += 5;\n  details.byline = '+5 (author present)';\n} else {\n  details.byline = '+0 (no author)';\n}\n\n// 2. Dateline presence (+5 points)\nconst hasDateline = Boolean(metadata.dateline);\nif (hasDateline) {\n  score += 5;\n  details.dateline = '+5 (location present)';\n} else {\n  details.dateline = '+0 (no dateline)';\n}\n\n// 3. Content length (+5 points for >500 chars, +3 for >200)\nif (content.length > 500) {\n  score += 5;\n  details.length = '+5 (>500 chars)';\n} else if (content.length > 200) {\n  score += 3;\n  details.length = '+3 (>200 chars)';\n} else {\n  details.length = '+0 (short content)';\n}\n\n// 4. Citations/sources mentioned (+5 points)\nconst citationPatterns = /according to|cited|reported|said|stated|officials?|spokesperson/gi;\nconst citationMatches = content.match(citationPatterns) || [];\nif (citationMatches.length >= 2) {\n  score += 5;\n  details.citations = `+5 (${citationMatches.length} citation phrases)`;\n} else if (citationMatches.length === 1) {\n  score += 2;\n  details.citations = '+2 (1 citation phrase)';\n} else {\n  details.citations = '+0 (no citations)';\n}\n\n// 5. Entity richness from AI extraction (+5 points)\nconst entities = metadata.entities || {};\nconst entityCount = (entities.people?.length || 0) + \n                   (entities.organizations?.length || 0) + \n                   (entities.locations?.length || 0);\nif (entityCount >= 5) {\n  score += 5;\n  details.entities = `+5 (${entityCount} entities)`;\n} else if (entityCount >= 2) {\n  score += 3;\n  details.entities = `+3 (${entityCount} entities)`;\n} else {\n  details.entities = '+0 (few entities)';\n}\n\nconst c2_score = Math.max(0, Math.min(25, score));\n\nreturn [{\n  json: {\n    ...item,\n    c2_content_quality: c2_score,\n    c2_details: details\n  }\n}];"
      },
      "id": "component-2-content",
      "name": "C2: Content Quality (0-25)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1360, 200],
      "notes": "REQ-AI-ML-004: Content quality analysis"
    },
    {
      "parameters": {
        "operation": "select",
        "query": "WITH similar_items AS (\n  SELECT i2.id, i2.title, i2.source_id, sp.base_score, sp.source_class,\n         1 - (i.embedding <=> i2.embedding) as similarity\n  FROM items i\n  JOIN items i2 ON i2.id != i.id AND i2.embedding IS NOT NULL\n  LEFT JOIN source_profiles sp ON i2.source_id = sp.id\n  WHERE i.id = $1::uuid\n    AND i2.published_at > NOW() - interval '7 days'\n    AND i2.status = 'scored'\n    AND sp.base_score >= 70\n  ORDER BY i.embedding <=> i2.embedding\n  LIMIT 10\n)\nSELECT COUNT(*) as corroborating_count,\n       COALESCE(AVG(similarity), 0) as avg_similarity,\n       COALESCE(json_agg(json_build_object('title', title, 'score', base_score, 'sim', similarity)), '[]') as sources\nFROM similar_items\nWHERE similarity > 0.7",
        "options": {
          "queryReplacement": "={{ $json.id }}"
        }
      },
      "id": "component-3-corroboration-query",
      "name": "Query Similar Items",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [1580, 300],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      },
      "notes": "REQ-AI-001: Find corroborating sources via vector similarity"
    },
    {
      "parameters": {
        "jsCode": "// REQ-AI-001: Component 3 - Corroboration (0-20 points)\n// Based on similar items from high-trust sources\n\nconst item = $('C2: Content Quality (0-25)').item.json;\nconst corroboration = $input.first().json;\n\nconst count = parseInt(corroboration.corroborating_count) || 0;\nconst avgSimilarity = parseFloat(corroboration.avg_similarity) || 0;\n\n// Scoring: Each high-trust corroborating source = 5 points (max 20)\nlet score = Math.min(20, count * 5);\n\n// Bonus for high similarity: if avg > 0.85, add 2 points\nif (avgSimilarity > 0.85 && count > 0) {\n  score = Math.min(20, score + 2);\n}\n\nconst c3_score = Math.max(0, Math.min(20, score));\n\nreturn [{\n  json: {\n    ...item,\n    c3_corroboration: c3_score,\n    c3_details: {\n      corroborating_sources: count,\n      avg_similarity: avgSimilarity.toFixed(3),\n      sources: corroboration.sources || []\n    }\n  }\n}];"
      },
      "id": "component-3-calculate",
      "name": "C3: Corroboration (0-20)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1800, 300],
      "notes": "REQ-AI-001: Corroboration scoring"
    },
    {
      "parameters": {
        "jsCode": "// REQ-AI-001: Component 4 - Freshness (0 to -10 penalty)\n// Age penalty: 0-5 days = 0, 5-10 days = -5, >10 days = -10\n\nconst item = $input.first().json;\nconst publishedAt = new Date(item.published_at);\nconst now = new Date();\nconst ageInDays = (now - publishedAt) / (1000 * 60 * 60 * 24);\n\nlet c4_score = 10; // Start with 10, apply penalties\nlet detail = '';\n\nif (ageInDays <= 2) {\n  c4_score = 10;\n  detail = '+10 (very fresh, <2 days)';\n} else if (ageInDays <= 5) {\n  c4_score = 7;\n  detail = '+7 (fresh, 2-5 days)';\n} else if (ageInDays <= 10) {\n  c4_score = 3;\n  detail = '+3 (aging, 5-10 days)';\n} else {\n  c4_score = 0;\n  detail = '+0 (stale, >10 days)';\n}\n\nreturn [{\n  json: {\n    ...item,\n    c4_freshness: c4_score,\n    c4_details: {\n      age_days: ageInDays.toFixed(1),\n      detail\n    }\n  }\n}];"
      },
      "id": "component-4-freshness",
      "name": "C4: Freshness (0-10)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2020, 300],
      "notes": "REQ-AI-001: Freshness/recency scoring"
    },
    {
      "parameters": {
        "jsCode": "// REQ-AI-001: Component 5 - Consistency (0-10 points)\n// Check if sentiment/claims align with high-trust sources\n// For MVP: simplified check based on sentiment alignment\n\nconst item = $input.first().json;\nconst metadata = item.ai_metadata || {};\nconst sentiment = metadata.sentiment || 'neutral';\n\n// Default to 5 (neutral) unless we have strong signal\nlet c5_score = 5;\nlet detail = 'Baseline consistency score';\n\n// If we have corroborating sources, boost consistency\nconst corrobCount = item.c3_details?.corroborating_sources || 0;\nif (corrobCount >= 2) {\n  c5_score = 8;\n  detail = 'High consistency (multiple corroborating sources)';\n} else if (corrobCount === 1) {\n  c5_score = 6;\n  detail = 'Moderate consistency (one corroborating source)';\n} else if (sentiment === 'neutral') {\n  c5_score = 5;\n  detail = 'Baseline (neutral sentiment, no contradictions found)';\n} else {\n  c5_score = 4;\n  detail = 'Unverified claims (no corroboration)';\n}\n\nreturn [{\n  json: {\n    ...item,\n    c5_consistency: Math.max(0, Math.min(10, c5_score)),\n    c5_details: { detail, sentiment }\n  }\n}];"
      },
      "id": "component-5-consistency",
      "name": "C5: Consistency (0-10)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2240, 300],
      "notes": "REQ-AI-001: Consistency check"
    },
    {
      "parameters": {
        "jsCode": "// REQ-AI-001 & REQ-AI-002: Calculate total trust score and classify\n// Total = C1 + C2 + C3 + C4 + C5\n// Max = 30 + 25 + 20 + 10 + 10 = 95\n// Capped at 95 (never show 100% certainty)\n\nconst item = $input.first().json;\n\nconst c1 = item.c1_source_credibility || 0;\nconst c2 = item.c2_content_quality || 0;\nconst c3 = item.c3_corroboration || 0;\nconst c4 = item.c4_freshness || 0;\nconst c5 = item.c5_consistency || 0;\n\nconst totalRaw = c1 + c2 + c3 + c4 + c5;\nconst totalScore = Math.max(15, Math.min(95, totalRaw)); // Floor at 15, cap at 95\n\n// REQ-AI-002: Classify trust level\nlet trustLevel = 'UNVERIFIED';\nif (totalScore >= 80) trustLevel = 'HIGH';\nelse if (totalScore >= 60) trustLevel = 'MEDIUM';\nelse if (totalScore >= 40) trustLevel = 'LOW';\nelse trustLevel = 'UNVERIFIED';\n\nreturn [{\n  json: {\n    ...item,\n    trust_score: totalScore,\n    trust_level: trustLevel,\n    score_breakdown: {\n      c1_source_credibility: c1,\n      c2_content_quality: c2,\n      c3_corroboration: c3,\n      c4_freshness: c4,\n      c5_consistency: c5,\n      total: totalRaw,\n      clamped: totalScore\n    }\n  }\n}];"
      },
      "id": "calculate-total",
      "name": "Calculate Total Score",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2460, 300],
      "notes": "REQ-AI-001 & REQ-AI-002: Sum components and classify"
    },
    {
      "parameters": {
        "jsCode": "// REQ-AI-003: Generate template-based explanation (no LLM)\n// Explain the score in human-readable format\n\nconst item = $input.first().json;\nconst b = item.score_breakdown;\nconst level = item.trust_level;\n\n// Build explanation parts\nconst parts = [];\n\n// Source credibility\nif (b.c1_source_credibility >= 20) {\n  parts.push(`This article comes from a highly credible source (${item.source_name || 'known outlet'})`);\n} else if (b.c1_source_credibility >= 10) {\n  parts.push(`The source has moderate credibility`);\n} else {\n  parts.push(`The source credibility could not be fully verified`);\n}\n\n// Content quality\nif (b.c2_content_quality >= 18) {\n  parts.push(`The content is well-structured with proper attribution`);\n} else if (b.c2_content_quality >= 12) {\n  parts.push(`The article contains some supporting details`);\n} else {\n  parts.push(`The content lacks detailed sourcing or attribution`);\n}\n\n// Corroboration\nconst corrobCount = item.c3_details?.corroborating_sources || 0;\nif (corrobCount >= 2) {\n  parts.push(`This story has been corroborated by ${corrobCount} other trusted sources`);\n} else if (corrobCount === 1) {\n  parts.push(`One other trusted source has reported similar information`);\n} else {\n  parts.push(`No corroborating reports from other trusted sources were found`);\n}\n\n// Freshness\nconst ageDays = parseFloat(item.c4_details?.age_days || 0);\nif (ageDays <= 2) {\n  parts.push(`This is breaking/recent news`);\n} else if (ageDays > 10) {\n  parts.push(`Note: This article is over 10 days old`);\n}\n\n// Build final explanation\nconst levelEmoji = {\n  'HIGH': '✅',\n  'MEDIUM': '⚠️',\n  'LOW': '⚠️',\n  'UNVERIFIED': '❓'\n};\n\nconst explanation = `${levelEmoji[level]} Trust Score: ${item.trust_score}/95 (${level})\\n\\n` +\n  parts.join('. ') + '.';\n\nconst explanation_json = {\n  score: item.trust_score,\n  level: level,\n  components: {\n    source_credibility: { score: b.c1_source_credibility, max: 30, detail: item.c1_details },\n    content_quality: { score: b.c2_content_quality, max: 25, detail: item.c2_details },\n    corroboration: { score: b.c3_corroboration, max: 20, detail: item.c3_details },\n    freshness: { score: b.c4_freshness, max: 10, detail: item.c4_details },\n    consistency: { score: b.c5_consistency, max: 10, detail: item.c5_details }\n  },\n  summary: parts.join('. ') + '.'\n};\n\nreturn [{\n  json: {\n    ...item,\n    trust_explanation: explanation,\n    trust_explanation_json: explanation_json\n  }\n}];"
      },
      "id": "generate-explanation",
      "name": "Generate Explanation",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2680, 300],
      "notes": "REQ-AI-003: Template-based explanation (no LLM)"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "WITH updated_item AS (\n  UPDATE items SET\n    status = 'scored'::processing_status,\n    trust_score = $2,\n    processed_at = NOW()\n  WHERE id = $1::uuid\n  RETURNING id\n)\nINSERT INTO trust_signals (\n  item_id,\n  score,\n  trust_level,\n  component_scores,\n  explanation,\n  calculated_at\n) VALUES (\n  $1::uuid,\n  $2,\n  $3,\n  $4::jsonb,\n  $5,\n  NOW()\n)\nRETURNING id",
        "options": {
          "queryReplacement": "={{ $json.id }},={{ $json.trust_score }},={{ $json.trust_level }},={{ JSON.stringify($json.score_breakdown) }},={{ $json.trust_explanation }}"
        }
      },
      "id": "save-trust-signal",
      "name": "Save Trust Signal",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [2900, 300],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      },
      "notes": "Update items.trust_score and insert trust_signals record"
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT record_workflow_success('WF3_Trust_Scoring')",
        "options": {}
      },
      "id": "record-success",
      "name": "Record Success",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [3120, 300],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT record_workflow_failure('WF3_Trust_Scoring', $1)",
        "options": {
          "queryReplacement": "={{ JSON.stringify({ error: $json.error || 'Unknown error', item_id: $json.id }) }}"
        }
      },
      "id": "record-failure",
      "name": "Record Failure",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.5,
      "position": [1140, 140],
      "credentials": {
        "postgres": {
          "id": "nura-postgres",
          "name": "Nura PostgreSQL"
        }
      }
    },
    {
      "parameters": {},
      "id": "noop-circuit-open",
      "name": "Skip (Circuit Open)",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [920, 400]
    }
  ],
  "connections": {
    "Schedule (5min)": {
      "main": [
        [
          {
            "node": "Check Circuit Breaker",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Circuit Breaker": {
      "main": [
        [
          {
            "node": "IF Circuit Open",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF Circuit Open": {
      "main": [
        [
          {
            "node": "Get Enriched Items",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Skip (Circuit Open)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Enriched Items": {
      "main": [
        [
          {
            "node": "C1: Source Credibility (0-30)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "C1: Source Credibility (0-30)": {
      "main": [
        [
          {
            "node": "C2: Content Quality (0-25)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "C2: Content Quality (0-25)": {
      "main": [
        [
          {
            "node": "Query Similar Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query Similar Items": {
      "main": [
        [
          {
            "node": "C3: Corroboration (0-20)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "C3: Corroboration (0-20)": {
      "main": [
        [
          {
            "node": "C4: Freshness (0-10)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "C4: Freshness (0-10)": {
      "main": [
        [
          {
            "node": "C5: Consistency (0-10)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "C5: Consistency (0-10)": {
      "main": [
        [
          {
            "node": "Calculate Total Score",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculate Total Score": {
      "main": [
        [
          {
            "node": "Generate Explanation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Explanation": {
      "main": [
        [
          {
            "node": "Save Trust Signal",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Trust Signal": {
      "main": [
        [
          {
            "node": "Record Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner"
  },
  "versionId": "wf3-trust-scoring-v2.0",
  "meta": {
    "templateCredsSetupCompleted": false,
    "instanceId": "nura-neural"
  },
  "id": "WF3_Trust_Scoring",
  "tags": [
    {
      "id": "trust",
      "name": "trust"
    },
    {
      "id": "scoring",
      "name": "scoring"
    },
    {
      "id": "mvp",
      "name": "mvp"
    }
  ],
  "__meta": {
    "requirements": ["REQ-AI-001", "REQ-AI-002", "REQ-AI-003", "REQ-AI-ML-004"],
    "description": "Trust Scoring Pipeline: 5-component scoring (Source, Quality, Corroboration, Freshness, Consistency) with template-based explanations",
    "cost_target": "$0.00 per execution (no AI calls, pure SQL + JavaScript)",
    "schedule": "Every 5 minutes, batch of 20 items",
    "scoring_formula": "C1(0-30) + C2(0-25) + C3(0-20) + C4(0-10) + C5(0-10) = Max 95"
  }
}
    "requirements": [
      "REQ-AI-001: 5-Component Trust Score (0-95 scale)",
      "REQ-AI-002: Source Type Base Scores",
      "REQ-AI-003: Template-Based Explanations"
    ],
    "trigger": "Database trigger on items.status = ENRICHED",
    "cost_target": "$0.00/day (no LLM calls)"
  }
}
